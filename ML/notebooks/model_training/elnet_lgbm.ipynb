{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e6eb33",
   "metadata": {},
   "source": [
    "# ElasticNet + LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b1284",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124ab1f",
   "metadata": {},
   "source": [
    "Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8a9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "from utils_yose import build_preprocessor\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from lightgbm import LGBMRegressor as LGBM\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892f758",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baebaa2",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757bd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"../../../data/housing_data/train.csv\"\n",
    "test_data = \"../../../data/housing_data/test.csv\"\n",
    "\n",
    "if os.path.exists(train_data):\n",
    "    df_train = pd.read_csv(train_data)\n",
    "else:\n",
    "    print(\"No se encuentra el archivo de entrenamiento\")\n",
    "    \n",
    "if os.path.exists(test_data):\n",
    "    df_test = pd.read_csv(test_data)\n",
    "else:\n",
    "    print(\"No se encuentra el archivo de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e44b7b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f53ad",
   "metadata": {},
   "source": [
    "Modelos base con los que se va a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb674431",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(df_train[\"SalePrice\"]).astype(float)\n",
    "X = df_train.drop([\"SalePrice\", \"Id\"], axis=1)\n",
    "\n",
    "rstate = 42\n",
    "base_models = {\n",
    "    \"elasticnet\": ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=rstate),\n",
    "    \"lgbm\": LGBM(n_estimators=3000, learning_rate=0.03, max_depth=-1,\n",
    "                 num_leaves=31, subsample=0.8, colsample_bytree=0.8,\n",
    "                 random_state=rstate, n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea5e0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b13dc",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo con Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba9a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3373\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.025324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3358\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score 12.028659\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3364\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.021956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3361\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 12.019795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3354\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 12.020663\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3350\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 12.026297\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3364\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.029436\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3359\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.022123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3360\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.023877\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3364\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 12.022444\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=rstate)\n",
    "oof_preds = {name: np.zeros(len(X), dtype=float) for name in base_models}\n",
    "oof_idx_mask = np.zeros(len(X), dtype=bool)\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X, y), 1):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    pre = build_preprocessor(X_tr)\n",
    "    fold_preds = {}\n",
    "    for name, mdl in base_models.items():\n",
    "        pipe = Pipeline([(\"pre\", clone(pre)), (\"model\", clone(mdl))])\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        p = pipe.predict(X_va)\n",
    "        fold_preds[name] = p\n",
    "    p_ens = np.mean(np.column_stack([fold_preds[n] for n in base_models]), axis=1)\n",
    "    rmse = root_mean_squared_error(y_va, p_ens)\n",
    "    r2 = r2_score(y_va, p_ens)\n",
    "    fold_metrics.append({\"fold\": fold, \"rmse\": float(rmse), \"r2\": float(r2)})\n",
    "    for name in base_models:\n",
    "        oof_preds[name][va_idx] = fold_preds[name]\n",
    "    oof_idx_mask[va_idx] = True\n",
    "\n",
    "cv_rmse_mean = float(np.mean([m[\"rmse\"] for m in fold_metrics]))\n",
    "cv_rmse_std  = float(np.std([m[\"rmse\"] for m in fold_metrics]))\n",
    "cv_r2_mean   = float(np.mean([m[\"r2\"] for m in fold_metrics]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d69da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac20dc",
   "metadata": {},
   "source": [
    "Optimizacion de los pesos del ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad9e8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3461\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 187\n",
      "[LightGBM] [Info] Start training from score 12.024057\n"
     ]
    }
   ],
   "source": [
    "grid_step = 0.05\n",
    "best = {\"weights\": None, \"rmse\": np.inf, \"r2\": -np.inf}\n",
    "M = np.column_stack([oof_preds[\"elasticnet\"], oof_preds[\"lgbm\"]])\n",
    "y_true = y.values\n",
    "\n",
    "for w1 in np.arange(0, 1 + 1e-9, grid_step):\n",
    "            w2 = 1 - w1\n",
    "            y_pred = w1 * oof_preds[\"elasticnet\"] + w2 * oof_preds[\"lgbm\"]\n",
    "            rmse = root_mean_squared_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            if rmse < best[\"rmse\"]:\n",
    "                best[\"weights\"] = (w1, w2)\n",
    "                best[\"rmse\"] = rmse\n",
    "                best[\"r2\"] = r2\n",
    "\n",
    "opt_weights = {\"elasticnet\": best[\"weights\"][0], \"lgbm\": best[\"weights\"][1]}\n",
    "\n",
    "pre_final = build_preprocessor(X)\n",
    "final_pipes = {}\n",
    "for name, mdl in base_models.items():\n",
    "    pipe = Pipeline([(\"pre\", clone(pre_final)), (\"model\", clone(mdl))])\n",
    "    pipe.fit(X, y)\n",
    "    final_pipes[name] = pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52522a93",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2bc07",
   "metadata": {},
   "source": [
    "Creamos el experimento de MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29141b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"HousePrices-2Ensemble\")\n",
    "\n",
    "sub_dir = \"../../../data/housing_submissions/elnet_lgbm\"\n",
    "os.makedirs(sub_dir, exist_ok=True)\n",
    "submission_path = os.path.join(sub_dir, \"submission_elnet_lgbm.csv\")\n",
    "\n",
    "meta = {\n",
    "    \"cv\": {\n",
    "        \"folds\": fold_metrics,\n",
    "        \"rmse_mean\": cv_rmse_mean, \"rmse_std\": cv_rmse_std,\n",
    "        \"r2_mean\": cv_r2_mean\n",
    "    },\n",
    "    \"ensemble_weights\": {k: float(v) for k, v in opt_weights.items()},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060c6dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4e752",
   "metadata": {},
   "source": [
    "Predicciones OOF/TEST y submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a116531",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop([\"Id\"], axis=1)\n",
    "preds = np.column_stack([\n",
    "    final_pipes[\"elasticnet\"].predict(X_test),\n",
    "    final_pipes[\"lgbm\"].predict(X_test)\n",
    "])\n",
    "\n",
    "w_vec = np.array([opt_weights[\"elasticnet\"], opt_weights[\"lgbm\"]], dtype=float)\n",
    "pred_log = preds @ w_vec\n",
    "pred_orig = np.expm1(pred_log)\n",
    "\n",
    "submission = pd.DataFrame({\"Id\": df_test[\"Id\"], \"SalePrice\": pred_orig})\n",
    "submission.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bb444",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723ba47",
   "metadata": {},
   "source": [
    "Firmamos el modelo para reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "899c33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(df_test.drop([\"Id\"], axis=1), pred_orig)\n",
    "\n",
    "with mlflow.start_run(run_name=\"ElasticNet+LGBM_Ensemble\") as run:\n",
    "    try:\n",
    "        enet_est = getattr(final_pipes[\"elasticnet\"], \"named_steps\", {}).get(\"model\") \\\n",
    "            or final_pipes[\"elasticnet\"].named_steps[list(final_pipes[\"elasticnet\"].named_steps.keys())[-1]]\n",
    "        lgbm_est = getattr(final_pipes[\"lgbm\"], \"named_steps\", {}).get(\"model\") \\\n",
    "            or final_pipes[\"lgbm\"].named_steps[list(final_pipes[\"lgbm\"].named_steps.keys())[-1]]\n",
    "        mlflow.log_param(\"random_state\", rstate)\n",
    "        mlflow.log_param(\"elasticnet_alpha\", getattr(enet_est, \"alpha\", None))\n",
    "        mlflow.log_param(\"elasticnet_l1_ratio\", getattr(enet_est, \"l1_ratio\", None))\n",
    "        mlflow.log_param(\"lgbm_n_estimators\", getattr(lgbm_est, \"n_estimators\", None))\n",
    "        mlflow.log_param(\"lgbm_max_depth\", getattr(lgbm_est, \"max_depth\", None))\n",
    "        mlflow.log_param(\"lgbm_num_leaves\", getattr(lgbm_est, \"num_leaves\", None))\n",
    "        mlflow.log_param(\"lgbm_learning_rate\", getattr(lgbm_est, \"learning_rate\", None))\n",
    "        mlflow.log_param(\"lgbm_subsample\", getattr(lgbm_est, \"subsample\", None))\n",
    "        mlflow.log_param(\"lgbm_colsample_bytree\", getattr(lgbm_est, \"colsample_bytree\", None))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    mlflow.log_param(\"n_features\", X_test.shape[1])\n",
    "    mlflow.log_param(\"ensemble_weights_elasticnet\", opt_weights[\"elasticnet\"])\n",
    "    mlflow.log_param(\"ensemble_weights_lgbm\", opt_weights[\"lgbm\"])\n",
    "    \n",
    "    mlflow.log_metric(\"cv_rmse_mean\", cv_rmse_mean)\n",
    "    mlflow.log_metric(\"cv_rmse_std\", cv_rmse_std)\n",
    "    mlflow.log_metric(\"cv_r2_mean\", cv_r2_mean)\n",
    "\n",
    "    mlflow.log_dict(meta, \"meta.json\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=final_pipes[\"elasticnet\"],\n",
    "        name=\"models_elasticnet\",\n",
    "        signature=signature,\n",
    "        input_example=X_test.head()\n",
    "    )\n",
    "    \n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=final_pipes[\"lgbm\"],\n",
    "        name=\"models_lgbm\",\n",
    "        signature=signature,\n",
    "        input_example=X_test.head()\n",
    "    )\n",
    "    \n",
    "    mlflow.log_artifact(submission_path, artifact_path=\"submissions\")\n",
    "    mlflow.set_experiment_tags({\n",
    "        \"task\": \"regression\",\n",
    "        \"dataset\": \"Kaggle-HousePrices-Competition\",\n",
    "        \"target\": \"SalePrice\",\n",
    "        \"target_transform\": \"log1p\",\n",
    "        \"inference_transform\": \"expm1\",\n",
    "        \"ensemble\": \"Weighted_ElasticNet+LGBM\"\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26985dcc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a5fef",
   "metadata": {},
   "source": [
    "Mostramos resultados en consola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b55b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESUMEN CV ===\n",
      "RMSE (mean ± std): 0.11708 ± 0.02141\n",
      "R2   (mean):       0.90927\n",
      "Pesos óptimos (OOF): {'elasticnet': np.float64(0.5), 'lgbm': np.float64(0.5)}\n",
      "Submission guardado en: ../../../data/housing_submissions/elnet_lgbm/submission_elnet_lgbm.csv\n",
      "Modelos y artefactos registrados en MLflow (ver en la UI del tracking server).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== RESUMEN CV ===\")\n",
    "print(f\"RMSE (mean ± std): {cv_rmse_mean:.5f} ± {cv_rmse_std:.5f}\")\n",
    "print(f\"R2   (mean):       {cv_r2_mean:.5f}\")\n",
    "print(\"Pesos óptimos (OOF):\", opt_weights)\n",
    "print(f\"Submission guardado en: {submission_path}\")\n",
    "print(\"Modelos y artefactos registrados en MLflow (ver en la UI del tracking server).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reto_housing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
