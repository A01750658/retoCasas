{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e6eb33",
   "metadata": {},
   "source": [
    "# Ensemble Regressor: ElasticNet + LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b1284",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124ab1f",
   "metadata": {},
   "source": [
    "Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e8a9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from lightgbm import LGBMRegressor as LGBM\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "sys.path.append('../../../utils/')\n",
    "from utils_yose import build_preprocessor, load_data\n",
    "from utils_yose import train_data, test_data\n",
    "from mlflow_setup import setup_mlflow\n",
    "\n",
    "sys.path.append('../../ensemble_2p/')\n",
    "from model_ensemble.ensemble import WeightedEnsemble\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "MODEL_NAME = \"HousePrices_Ensemble\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892f758",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baebaa2",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "757bd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, X_test, df_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e44b7b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f53ad",
   "metadata": {},
   "source": [
    "Modelos base con los que se va a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb674431",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(df_train[\"SalePrice\"]).astype(float)\n",
    "X = df_train.drop([\"SalePrice\", \"Id\"], axis=1)\n",
    "\n",
    "rstate = 42\n",
    "base_models = {\n",
    "    \"elasticnet\": ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=rstate),\n",
    "    \"lgbm\": LGBM(n_estimators=3000, learning_rate=0.03, max_depth=-1,\n",
    "                 num_leaves=31, subsample=0.8, colsample_bytree=0.8,\n",
    "                 random_state=rstate, n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea5e0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b13dc",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo con Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bba9a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3373\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.025324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3358\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score 12.028659\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3364\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.021956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3361\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 12.019795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3354\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 12.020663\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3350\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 12.026297\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3364\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.029436\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3359\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.022123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3360\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 12.023877\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3364\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 12.022444\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=rstate)\n",
    "oof_preds = {name: np.zeros(len(X), dtype=float) for name in base_models}\n",
    "oof_idx_mask = np.zeros(len(X), dtype=bool)\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X, y), 1):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    pre = build_preprocessor(X_tr)\n",
    "    fold_preds = {}\n",
    "    for name, mdl in base_models.items():\n",
    "        pipe = Pipeline([(\"pre\", clone(pre)), (\"model\", clone(mdl))])\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        p = pipe.predict(X_va)\n",
    "        fold_preds[name] = p\n",
    "    p_ens = np.mean(np.column_stack([fold_preds[n] for n in base_models]), axis=1)\n",
    "    rmse = root_mean_squared_error(y_va, p_ens)\n",
    "    r2 = r2_score(y_va, p_ens)\n",
    "    fold_metrics.append({\"fold\": fold, \"rmse\": float(rmse), \"r2\": float(r2)})\n",
    "    for name in base_models:\n",
    "        oof_preds[name][va_idx] = fold_preds[name]\n",
    "    oof_idx_mask[va_idx] = True\n",
    "\n",
    "cv_rmse_mean = float(np.mean([m[\"rmse\"] for m in fold_metrics]))\n",
    "cv_rmse_std  = float(np.std([m[\"rmse\"] for m in fold_metrics]))\n",
    "cv_r2_mean   = float(np.mean([m[\"r2\"] for m in fold_metrics]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d69da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac20dc",
   "metadata": {},
   "source": [
    "Optimizacion de los pesos del ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ad9e8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3461\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 187\n",
      "[LightGBM] [Info] Start training from score 12.024057\n"
     ]
    }
   ],
   "source": [
    "grid_step = 0.05\n",
    "best = {\"weights\": None, \"rmse\": np.inf, \"r2\": -np.inf}\n",
    "M = np.column_stack([oof_preds[\"elasticnet\"], oof_preds[\"lgbm\"]])\n",
    "y_true = y.values\n",
    "\n",
    "for w1 in np.arange(0, 1 + 1e-9, grid_step):\n",
    "            w2 = 1 - w1\n",
    "            y_pred = w1 * oof_preds[\"elasticnet\"] + w2 * oof_preds[\"lgbm\"]\n",
    "            rmse = root_mean_squared_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            if rmse < best[\"rmse\"]:\n",
    "                best[\"weights\"] = (w1, w2)\n",
    "                best[\"rmse\"] = rmse\n",
    "                best[\"r2\"] = r2\n",
    "\n",
    "opt_weights = {\"elasticnet\": best[\"weights\"][0], \"lgbm\": best[\"weights\"][1]}\n",
    "\n",
    "pre_final = build_preprocessor(X)\n",
    "final_pipes = {}\n",
    "for name, mdl in base_models.items():\n",
    "    pipe = Pipeline([(\"pre\", clone(pre_final)), (\"model\", clone(mdl))])\n",
    "    pipe.fit(X, y)\n",
    "    final_pipes[name] = pipe\n",
    "\n",
    "for model in final_pipes:\n",
    "    model_path = os.path.join('../model_ensemble/ensemble_model/', f\"model_{model}.pkl\")\n",
    "    joblib.dump(final_pipes[model], model_path)\n",
    "\n",
    "weights_json = \"../model_ensemble/ensemble_weights/weights.json\"\n",
    "json.dump({\n",
    "    \"w_elnet\": float(opt_weights[\"elasticnet\"]),\n",
    "    \"w_lgbm\":  float(opt_weights[\"lgbm\"])\n",
    "}, open(weights_json, \"w\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f60e5b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723ba47",
   "metadata": {},
   "source": [
    "Creamos y guardamos con MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c33e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/27 19:25:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/27 19:25:18 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 1535.81it/s]\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 1781.78it/s]\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 433.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI del modelo: runs:/9169acf3f68d48d8b375039ff509abc7/ensemble_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 2/2 [00:00<00:00, 798.38it/s]\n",
      "Downloading artifacts: 100%|██████████| 10/10 [00:00<00:00, 939.14it/s] \n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 1633.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: ../model_ensemble/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_example = pd.read_csv(\"../../../../data/housing_data/sample_submission.csv\").drop([\"Id\"], axis=1)\n",
    "ensemble = WeightedEnsemble()\n",
    "signature = infer_signature(df_test, prediction_example)\n",
    "\n",
    "base = Path(\"~/Code/retoCasas/ML\").expanduser().resolve()\n",
    "base.mkdir(parents=True, exist_ok=True)\n",
    "mlflow.set_tracking_uri(f\"file:{base.as_posix()}\")\n",
    "os.environ.pop(\"MLFLOW_EXPERIMENT_ID\", None)\n",
    "\n",
    "EXP_NAME = \"HousePrices-Competition\"\n",
    "exp = mlflow.get_experiment_by_name(EXP_NAME)\n",
    "if exp is None:\n",
    "    exp_id = mlflow.create_experiment(EXP_NAME)\n",
    "else:\n",
    "    exp_id = exp.experiment_id\n",
    "\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=\"ElasticNet+LGBM_Ensemble\") as run:\n",
    "    \n",
    "    try:\n",
    "        enet_est = getattr(final_pipes[\"elasticnet\"], \"named_steps\", {}).get(\"model\") \\\n",
    "            or final_pipes[\"elasticnet\"].named_steps[list(final_pipes[\"elasticnet\"].named_steps.keys())[-1]]\n",
    "        lgbm_est = getattr(final_pipes[\"lgbm\"], \"named_steps\", {}).get(\"model\") \\\n",
    "            or final_pipes[\"lgbm\"].named_steps[list(final_pipes[\"lgbm\"].named_steps.keys())[-1]]\n",
    "        mlflow.log_param(\"random_state\", rstate)\n",
    "        mlflow.log_param(\"elasticnet_alpha\", getattr(enet_est, \"alpha\", None))\n",
    "        mlflow.log_param(\"elasticnet_l1_ratio\", getattr(enet_est, \"l1_ratio\", None))\n",
    "        mlflow.log_param(\"lgbm_n_estimators\", getattr(lgbm_est, \"n_estimators\", None))\n",
    "        mlflow.log_param(\"lgbm_max_depth\", getattr(lgbm_est, \"max_depth\", None))\n",
    "        mlflow.log_param(\"lgbm_num_leaves\", getattr(lgbm_est, \"num_leaves\", None))\n",
    "        mlflow.log_param(\"lgbm_learning_rate\", getattr(lgbm_est, \"learning_rate\", None))\n",
    "        mlflow.log_param(\"lgbm_subsample\", getattr(lgbm_est, \"subsample\", None))\n",
    "        mlflow.log_param(\"lgbm_colsample_bytree\", getattr(lgbm_est, \"colsample_bytree\", None))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    train_ds = mlflow.data.from_pandas(df_train, source=\"data/housing_data/train.csv\")\n",
    "    mlflow.log_input(train_ds, context=\"training\")\n",
    "    \n",
    "    test_ds = mlflow.data.from_pandas(pd.DataFrame(df_test), source=\"data/housing_data/test.csv\")\n",
    "    mlflow.log_input(test_ds, context=\"inference\")\n",
    "    \n",
    "    mlflow.log_param(\"n_features\", df_test.shape[1])\n",
    "    mlflow.log_param(\"n_samples\", df_train.shape[0])\n",
    "    mlflow.log_param(\"n_folds\", kf.get_n_splits())\n",
    "    mlflow.log_param(\"ensemble_weights_elasticnet\", opt_weights[\"elasticnet\"])\n",
    "    mlflow.log_param(\"ensemble_weights_lgbm\", opt_weights[\"lgbm\"])\n",
    "    \n",
    "    mlflow.log_metric(\"cv_rmse_mean\", cv_rmse_mean)\n",
    "    mlflow.log_metric(\"cv_rmse_std\", cv_rmse_std)\n",
    "    mlflow.log_metric(\"cv_r2_mean\", cv_r2_mean)\n",
    "    \n",
    "    mlflow.pyfunc.log_model(\n",
    "        python_model = ensemble,\n",
    "        artifacts={\n",
    "            \"weights_json\": weights_json,\n",
    "            \"model_elasticnet_pkl\": \"../model_ensemble/ensemble_model/model_elasticnet.pkl\",\n",
    "            \"model_lgbm_pkl\": \"../model_ensemble/ensemble_model/model_lgbm.pkl\"\n",
    "        },\n",
    "        signature=signature,\n",
    "        name=\"ensemble_model\",\n",
    "        input_example=df_test.head(),\n",
    "    )\n",
    "    mlflow.log_artifact(train_data, artifact_path=\"data\")\n",
    "    mlflow.log_artifact(test_data, artifact_path=\"data\")\n",
    "\n",
    "    mlflow.log_artifact(weights_json, artifact_path=\"ensemble_weights\")\n",
    "    mlflow.log_artifact(\"../model_ensemble/ensemble_model/model_elasticnet.pkl\", artifact_path=\"ensemble_model\")\n",
    "    mlflow.log_artifact(\"../model_ensemble/ensemble_model/model_lgbm.pkl\", artifact_path=\"ensemble_model\")\n",
    "\n",
    "    mlflow.set_tags({\n",
    "        \"task\": \"regression\",\n",
    "        \"dataset\": \"Kaggle-HousePrices-Competition\",\n",
    "        \"target\": \"SalePrice\",\n",
    "        \"target_transform\": \"log1p\",\n",
    "        \"inference_transform\": \"expm1\",\n",
    "        \"ensemble\": \"Weighted_ElasticNet+LGBM\"\n",
    "    })\n",
    "    MODEL_URI = f\"runs:/{run.info.run_id}/ensemble_model\"\n",
    "    print(\"URI del modelo:\", f\"runs:/{run.info.run_id}/ensemble_model\")\n",
    "\n",
    "client = MlflowClient()\n",
    "remote_path = ['ensemble_model', 'ensemble_weights']\n",
    "local_dir = \"../model_ensemble/\"\n",
    "for path in remote_path:\n",
    "    client.download_artifacts(run_id=run.info.run_id, path=path, dst_path=local_dir)\n",
    "\n",
    "print(\"Guardado en:\", local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26985dcc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a5fef",
   "metadata": {},
   "source": [
    "Mostramos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89b55b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESUMEN CV ===\n",
      "RMSE (mean ± std): 0.11708 ± 0.02141\n",
      "R2   (mean):       0.90927\n",
      "Pesos óptimos (OOF): {'elasticnet': np.float64(0.5), 'lgbm': np.float64(0.5)}\n",
      "Modelos y artefactos registrados en MLflow (ver en la UI del tracking server).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== RESUMEN CV ===\")\n",
    "print(f\"RMSE (mean ± std): {cv_rmse_mean:.5f} ± {cv_rmse_std:.5f}\")\n",
    "print(f\"R2   (mean):       {cv_r2_mean:.5f}\")\n",
    "print(\"Pesos óptimos (OOF):\", opt_weights)\n",
    "print(\"Modelos y artefactos registrados en MLflow (ver en la UI del tracking server).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8717e8ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e5962",
   "metadata": {},
   "source": [
    "### Deployment del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b36a85",
   "metadata": {},
   "source": [
    "Registrar versiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7096c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'HousePrices_Ensemble'.\n",
      "2025/08/27 19:25:36 WARNING mlflow.tracking._model_registry.fluent: Run with id 9169acf3f68d48d8b375039ff509abc7 has no artifacts at artifact path 'ensemble_model', registering model based on models:/m-04a4c4594334482196b5e9ef516044be instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version registrada: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'HousePrices_Ensemble'.\n"
     ]
    }
   ],
   "source": [
    "mv = mlflow.register_model(\n",
    "    model_uri = MODEL_URI,\n",
    "    name = MODEL_NAME,\n",
    "    tags = {\n",
    "        \"task\": \"regression\",\n",
    "        \"dataset\": \"Kaggle-HousePrices-Competition\",\n",
    "        \"target\": \"SalePrice\",\n",
    "        \"target_transform\": \"log1p\",\n",
    "        \"inference_transform\": \"expm1\",\n",
    "        \"ensemble\": \"Weighted_ElasticNet+LGBM\"\n",
    "    },\n",
    ")\n",
    "\n",
    "client.set_registered_model_tag(mv.name, \"created_by\", \"Yose Sotomayor\")\n",
    "client.set_registered_model_alias(mv.name, \"challenger\", version=mv.version)\n",
    "print(\"Version registrada:\", mv.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0852be",
   "metadata": {},
   "source": [
    "Transicionar versiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2eb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_registered_model_alias(MODEL_NAME, \"challenger\")\n",
    "client.set_registered_model_alias(MODEL_NAME, \"champion\", mv.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a696c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e90d75d",
   "metadata": {},
   "source": [
    "Guardar los datos para subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126865a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Registered Model with name=HousePrices_Ensemble not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels:/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m@champion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m preds_orig  = model.predict(df_test)\n\u001b[32m      5\u001b[39m sub_dir = \u001b[33m\"\u001b[39m\u001b[33m../../../data/housing_submissions/elnet_lgbm\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/tracing/provider.py:461\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    460\u001b[39m     is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    463\u001b[39m     enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:1131\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[39m\n\u001b[32m   1127\u001b[39m         entity_list.append(Entity(job=job_entity))\n\u001b[32m   1129\u001b[39m     lineage_header_info = LineageHeaderInfo(entities=entity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m local_path = \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineage_header_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineage_header_info\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[32m   1136\u001b[39m     model_requirements = _get_pip_requirements_from_model_path(local_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/tracking/artifact_utils.py:115\u001b[39m, in \u001b[36m_download_artifact_from_uri\u001b[39m\u001b[34m(artifact_uri, output_path, lineage_header_info, tracking_uri)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    tracking_uri: The tracking URI to be used when downloading artifacts.\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    114\u001b[39m root_uri, artifact_path = _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m repo = \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/store/artifact/artifact_repository_registry.py:143\u001b[39m, in \u001b[36mget_artifact_repository\u001b[39m\u001b[34m(artifact_uri, tracking_uri)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_artifact_repository\u001b[39m(\n\u001b[32m    127\u001b[39m     artifact_uri: \u001b[38;5;28mstr\u001b[39m, tracking_uri: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    128\u001b[39m ) -> ArtifactRepository:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[32m    131\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m \u001b[33;03m        requirements.\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_artifact_repository_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/store/artifact/artifact_repository_registry.py:81\u001b[39m, in \u001b[36mArtifactRepositoryRegistry.get_artifact_repository\u001b[39m\u001b[34m(self, artifact_uri, tracking_uri)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m     78\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._registry.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/store/artifact/models_artifact_repo.py:72\u001b[39m, in \u001b[36mModelsArtifactRepository.__init__\u001b[39m\u001b[34m(self, artifact_uri, tracking_uri)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_version = \u001b[38;5;28mself\u001b[39m.repo.model_version\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     68\u001b[39m     (\n\u001b[32m     69\u001b[39m         \u001b[38;5;28mself\u001b[39m.model_name,\n\u001b[32m     70\u001b[39m         \u001b[38;5;28mself\u001b[39m.model_version,\n\u001b[32m     71\u001b[39m         underlying_uri,\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     ) = \u001b[43mModelsArtifactRepository\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_model_uri_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.repo = get_artifact_repository(underlying_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/store/artifact/models_artifact_repo.py:123\u001b[39m, in \u001b[36mModelsArtifactRepository._get_model_uri_infos\u001b[39m\u001b[34m(uri)\u001b[39m\n\u001b[32m    119\u001b[39m databricks_profile_uri = (\n\u001b[32m    120\u001b[39m     get_databricks_profile_uri_from_artifact_uri(uri) \u001b[38;5;129;01mor\u001b[39;00m mlflow.get_registry_uri()\n\u001b[32m    121\u001b[39m )\n\u001b[32m    122\u001b[39m client = MlflowClient(registry_uri=databricks_profile_uri)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m name_and_version_or_id = \u001b[43mget_model_name_and_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(name_and_version_or_id) == \u001b[32m1\u001b[39m:\n\u001b[32m    125\u001b[39m     name = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/store/artifact/utils/models.py:146\u001b[39m, in \u001b[36mget_model_name_and_version\u001b[39m\u001b[34m(client, models_uri)\u001b[39m\n\u001b[32m    143\u001b[39m     client = client._get_registry_client()\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     mv = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_model_version_by_alias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_alias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_name, mv.version\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_name, \u001b[38;5;28mstr\u001b[39m(_get_latest_model_version(client, model_name, model_stage))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/tracking/_model_registry/client.py:474\u001b[39m, in \u001b[36mModelRegistryClient.get_model_version_by_alias\u001b[39m\u001b[34m(self, name, alias)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model_version_by_alias\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, alias):\n\u001b[32m    464\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the model version instance by name and alias.\u001b[39;00m\n\u001b[32m    465\u001b[39m \n\u001b[32m    466\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    472\u001b[39m \n\u001b[32m    473\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_model_version_by_alias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/store/model_registry/file_store.py:1058\u001b[39m, in \u001b[36mFileStore.get_model_version_by_alias\u001b[39m\u001b[34m(self, name, alias)\u001b[39m\n\u001b[32m   1055\u001b[39m     latest_version = \u001b[38;5;28mnext\u001b[39m(v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_latest_versions(name) \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_model_version(name, latest_version.version)\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m alias_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_registered_model_alias_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exists(alias_path):\n\u001b[32m   1060\u001b[39m     version = read_file(os.path.dirname(alias_path), os.path.basename(alias_path))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/Reto_housing/lib/python3.12/site-packages/mlflow/store/model_registry/file_store.py:998\u001b[39m, in \u001b[36mFileStore._get_registered_model_alias_path\u001b[39m\u001b[34m(self, name, alias)\u001b[39m\n\u001b[32m    996\u001b[39m registered_model_path = \u001b[38;5;28mself\u001b[39m._get_registered_model_path(name)\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(registered_model_path):\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    999\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRegistered Model with name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1000\u001b[39m         RESOURCE_DOES_NOT_EXIST,\n\u001b[32m   1001\u001b[39m     )\n\u001b[32m   1002\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m os.path.join(\n\u001b[32m   1003\u001b[39m     registered_model_path, FileStore.REGISTERED_MODELS_ALIASES_FOLDER_NAME, alias\n\u001b[32m   1004\u001b[39m )\n",
      "\u001b[31mMlflowException\u001b[39m: Registered Model with name=HousePrices_Ensemble not found"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(f\"models:/{MODEL_NAME}@champion\")\n",
    "\n",
    "preds_orig  = model.predict(df_test)\n",
    "\n",
    "sub_dir = \"../../../data/housing_submissions/elnet_lgbm\"\n",
    "os.makedirs(sub_dir, exist_ok=True)\n",
    "submission_path = os.path.join(sub_dir, \"submission_elnet_lgbm.csv\")\n",
    "\n",
    "\n",
    "df_sub = pd.DataFrame({\"Id\": X_test[\"Id\"], \"SalePrice\": preds_orig})\n",
    "df_sub.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7df61a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reto_housing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
